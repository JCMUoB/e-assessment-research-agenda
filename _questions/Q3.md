---
question_code: Q3 
question_num: 3 
question_text: Under what circumstances is diagnosing errors/misconceptions worth the extra effort, as compared with generally addressing errors known to be typical? 

question_code_meeting1: B5 
question_code_conf: EF3 

contributors: 
- timlowe
- georgekinnear

---
Diagnosing and responding in detail to students' specific errors/misconceptions has become perceived as highly valuable, and e-assessment systems have features that can facilitate this. But might it be more efficient overall to avoid attempting to diagnose errors after the fact, and instead "treat" everyone by addressing known typical errors in other ways?

## What motivates this question?

Recent research suggests that "elaborated feedback" is more useful than simply giving correct/incorrect feedback (Attali & van der Kleij, 2017).

However, devising this feedback and implementing it in an e-assessment system requires up-front effort from the teacher. That effort could perhaps be better spent in other ways. 

Moreover, such specific feedback may be more valuable where the difficulty is in some way unusual and requires bespoke intervention -- something that is perhaps better achieved with a 1-1 interaction rather than being mediated through an e-assessment system.


## What might an answer look like?

Would need to decide what consitutes "extra effort" which may depend on the life of the quiz and the number of expected attempts. It may also be the case that some diagnosis can happen with very little extra effort, e.g. the way that some STACK ["answer tests"](http://docs.stack-assessment.org/en/Authoring/Answer_tests/) provide feedback on common errors. Similarly, e-assessment systems may have features to report on frequent wrong answers, that could help the teacher to diagnose common errors.

The question asks "under what circumstances?" and these may include:

* Mode of study of the student. Diagnosing errors may be of more importance to a student without easy access to a teacher.
* Topic. Some topics may have a small number of very well-defined errors/misconceptions; for other topics we may just not know, or we may know that difficulties are very diverse.

Determining whether it is "worth" the extra effort could be based on quantitative measures (e.g. studying whether the presence of diagnostic feedback during practice leads to better performance on a subsequent test) or qualitative analysis (e.g. of students' perceptions of the usefulness of the feedback).

## Related questions

* This is closely related to [Q4](Q4) which asks whether common errors might be better addressed up-front rather than in feedback. (In fact, Q4 is perhaps just a sub-question of this one, as an example of a specific way of "generally addressing errors known to be typical").
* The issue of common errors is also addressed in [Q1](Q1) [Q2](Q2) [Q5](Q5).
* See [Q5](Q5) for fleshing out of a similar question by a group at the conference 27.01.21

## References

Attali, Y., & van der Kleij, F. (2017). Effects of feedback elaboration and feedback timing during computer-based practice in mathematics problem solving. Computers and Education, 110, 154â€“169. https://doi.org/10.1016/j.compedu.2017.03.012
