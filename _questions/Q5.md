---
question_code: Q5 
question_num: 5 
question_text: What common errors do students make when answering online assessment questions?

question_code_meeting1: B14 
question_code_conf: EF5 

contributors: 
- timlowe
- ianjones
- timhunt
- ikon625
- niclaslarson
- prowlett
---

Student make mistate for a range of reasons, from the trivial to the conceptual. We are interested in conceptual errors, so we can improve our teaching, and perhaps reveal tricky topics. We are interested in errors made interpreting questions, so we can author less ambiguously. Conceptual errors are likely to be different for each area of mathematical knowledge.

Common errors may be due to
- Lack of request or requirement for explicit working, in contrast to paper-based assessments (see also [Q1](Q1) )
- Students are used to quickly clicking buttons and filling in textboxes; do they realise adequately that an online maths test is not a social media survey?  (see also [Q1](Q1) )
- Mistakes due to the technology: clicked the button too quickly
- Errors of input: students: used the wrong syntax
- Careless errors: slips in working
- Errors of intepreration: students answered the wrong question
- Mathematical errors made when answering the question

We are probably more interested in the later categories, but to revieal those issues, we may first need to elimitate more trivial causes of error.

## What motivates this question?

An answer to this question might help:

- Creator's of Assessment systems produce systems which avoid technical and input issues, to the assessment outcomes depend on the mathematics.
- Teachers may gain a better understand of what are tricky topics, that need to be taught with care.
- It may lead to better techniques for question authors, to create questions that are not liable to misinterpretation.
- ... and where feedback for students should be added for common errors.

## What might an answer look like?

Online assessment systems store all responses by all students in a database. This is a large pool of data that could be mined.

It may be difficult to tell whether a wrong student answer is due to misinterpretation of the question or misscalcualtion. 
It would be interesting to identify those errrors that persist across different variants of the same question.

The answer is likely to be different in dofferemt subject areas. Thus the answer will probably be a catalogue of the typical misconceptions in certain areas of mathematical knowledge. Further analysis might reveal the tacit models students have that lead to those errors.

There are various papers that have attempted to examine student work for misconceptions (Jordan et al., 2003; Greenhow & Gill, 2004; Walker, Gwynllyw & Henderson, 2015). Note that Walker, Gwynllyw & Henderson (2015) completed a post-assessment analysis of e-assessment data and found a large number of errors that were made quite infrequently by students, suggesting pre-empting student errors may be quite difficult in practice.

## Related questions

* There are a group of related questions about common errors: [Q1](Q1) [Q2](Q2) [Q3](Q3) [Q4](Q4)

* [Q1](Q1) Do the errors students make in e-assessments differ from those they make in paper-based assessments? Are the answers found here are CAA-specific, or generally applicable.

* This question perhaps precedes [Q2](Q2) What are the approaches to detecting and feeding back on students' errors?.

* This question probably precedes [Q1](Q1)Do the errors students make in e-assessments differ from those they make in paper-based assessments?  One needs to separately identify errors made in online and paper submissions (separately) before comparing the two.

* The issue of student input of mathematics is related to [Q50](Q50).

## References

Greenhow, M. & Gill, M. (2004). Setting objective tests in mathematics using QM Perception. Proceedings of the 8th Computer Assisted Assessment Conference, Loughborough University, 6th-7th July 2004 (pp. 115-126). Loughborough: Loughborough University.

Jordan, S. (2013). E-assessment: Past, present and future. New Directions, 9(1), 87-106. https://doi.org/10.11120/ndir.2013.00009

Walker, P., Gwynllyw, D.R. & Henderson, K.L. (2015). Diagnosing student errors in e-Assessment questions. Teaching Mathematics and its Applications, 34(3), 160-170. https://doi.org/10.1093/teamat/hrv010
