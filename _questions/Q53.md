---
question_code: Q53 
question_num: 53 
question_text: How do students engage with automated feedback, and are there any differences with how they would respond to the same feedback from a teacher? 

question_code_meeting1:  
question_code_conf: NEW1 

contributors: 
- ikon625
- prowlett
- niclaslarson
- georgekinnear

---

## What motivates this question?

How students engage with feedback and what they do next, whether it promotes positive learning behaviour, is clearly important to close the loop of assessment for learning. Yet apparently little is known about what students do when they get feedback. Do they read it and engage with it? What do they do next? If they got a question wrong, do they attempt relevant learning and reattempt the assessment item? If they get positive feedback, do they set themselves new learning goals to advance to the next level of the topic? 

A recent "critical scoping review" of research on student perceptions of assessment feedback (Van der Kleij and Lipnevich, 2020) provides useful background information. Out of 164 studies included in the review, only 4 were based in mathematics. Similarly, from the summary of each study presented in the supplementary materials, a search for "computer" suggested that very few of the included studies were related to automated feedback (studies 43, 89, 90, 148).

## What might an answer look like?

A questionnaire asking students to report their behaviour could be used. It could be that tracking within an integrated learning and assessment system could be used to track what students do when engaging with feedback and what they do afterwards. 

The framework presented by Van der Kleij and Lipnevich (2020, Fig. 3) could also inform the selection of methods, particularly as they highlight methodological concerns with survey-based research.

## Related questions

* The issue of student engagement with automated feedback overlaps with [Q35: Why How do mathematics students interact with an e-assessment system?](Q35)
* The issue of relevance of feedback is relevant to [Q6: How can content-specific features of provided feedback, for instance explanations with examples versus generic explanations, support students' learning?](Q6).
* Some discussion of student preference re. automated and human feedback is given in [Q13: In what circumstances is instant feedback from automated marking preferable to marking by hand?](Q13).
* The way students engage with feedback may be different if the e-assessment system gives feedback in a way that emulates teacher approaches, as in:
  - [Q10: How can feedback that is dynamically tailored to the student’s level of mathematical expertise, for example by taking into account the student’s history on performance of similar tasks or performance in a task sequence prior to the current task in this sequence, help a student use feedback on mathematical  tasks effectively?](Q10)
  - [Q11: How useful for students’ long-term learning is feedback that gives a series of follow-up questions, from a decision tree, versus a single terminal piece of feedback that tells the students exactly what they should have done?](Q11)
  - [Q12: What are the relative benefits of e-assessment giving feedback on a student’s set of responses (e.g. “two of these answers are wrong – find which ones and correct them”), rather than individual ones separately?])(Q12)

## References

Van der Kleij, F. M., & Lipnevich, A. A. (2020). Student perceptions of assessment feedback: a critical scoping review and call for research. Educational Assessment, Evaluation and Accountability, 33(2), 345–373. https://doi.org/10.1007/s11092-020-09331-x