---
question_code: Q1
question_num: 1
question_text: Do the errors students make in e-assessments differ from those they make in paper-based assessments?

question_code_meeting1: A11
question_code_conf: EF1

contributors:
- timlowe
- prowlett

---
Does answering questions through the medium of a computer-based assignment (with the consequential need to input answers using some form of computer syntax or mathematics editor) mean students make different errors to those made on paper? Are there more, or different types of, transcription error? Can computer based assessments detect errors and misconceptions that are not possible to detect in paper based written answers?

## What motivates this question?

An answer to this question might help alleviate the fears of colleagues reluctant to engage with computer based assessment. It might also help identify errors or misconceptions that are hard to detect on paper. (For example, the student who thought the notation for natural logarithm was "In" (captial-eye, en) as they had always misread ln. This would be hard to detect on paper, but on a computer causes answers to be marked as wrong.)

Sangwin (2015) highlights the difference between a typed response being "invalid" and "wrong", saying that floating point numbers, rational coefficients not in lowest terms or an expression entered in place as of an equation might be invalid, in certain circumstances, rather than wrong.

An issue is that when a system responds to an error, the student may be unaware whether the error is mathematical or typographical in nature (Jones, 2008).

## What might an answer look like?

A study to answer this question might split a group of students: half doing an assessment on paper and half on computer and compare errors made. A large sample would be needed, ideally of students likely to make a significant number of errors. This might be informed by the answer to [Q5](Q5) which could first identify common errors in computer assessments to guide this study. A preliminary study to identify common errors made on paper might also be needed.


## Related questions


* The issue of common errors is relate to [Q1](Q1) [Q2](Q2) [Q3](Q3) [Q4](Q4)

* This is related to [Q49](49):Are there differences in performance on mathematics problems presented and carried out on paper versus on the computer?

* See [Q5](Q5) for fleshing out of a similar question by a group at the conference 27.01.21. This question probably follows Q5: One needs to separately identify errors made in online and paper submissions (separately) before comparing the two,


## References

Jones, I.S. (2008). Computer-aided assessment questions in engineering mathematics using MapleTA. International Journal of Mathematical Education in Science and Technology, 39(3), 341-356. https://doi.org/10.1080/00207390701734523

Sangwin, C. (2015). Computer Aided Assessment of Mathematics Using STACK. In S.J. Cho (Ed.), Selected Regular Lectures from the 12th International Congress on Mathematical Education (pp. 698-713). Cham: Springer. https://doi.org/10.1007/978-3-319-17187-6_39
