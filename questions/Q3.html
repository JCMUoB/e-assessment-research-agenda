<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Q3 - Research agenda for e-assessment of university mathematics</title>
<meta name="description" content="Diagnosing and responding in detail to students’ specific errors/misconceptions has become perceived as highly valuable, and e-assessment systems have features that can facilitate this. But might it be more efficient overall to avoid attempting to diagnose errors after the fact, and instead “treat” everyone by addressing known typical errors in other ways?">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Research agenda for e-assessment of university mathematics">
<meta property="og:title" content="Q3">
<meta property="og:url" content="/e-assessment-research-agenda/questions/Q3.html">


  <meta property="og:description" content="Diagnosing and responding in detail to students’ specific errors/misconceptions has become perceived as highly valuable, and e-assessment systems have features that can facilitate this. But might it be more efficient overall to avoid attempting to diagnose errors after the fact, and instead “treat” everyone by addressing known typical errors in other ways?">







  <meta property="article:published_time" content="2021-10-14T14:01:36+00:00">






<link rel="canonical" href="/e-assessment-research-agenda/questions/Q3.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "/e-assessment-research-agenda/"
    
  }
</script>







<!-- end _includes/seo.html -->




<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/e-assessment-research-agenda/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <style>
ul.question_links a {
	text-decoration: none;
}
.feature__item ul {
	margin-top: 0;
}
.feature__item p {
	margin-bottom: 0;
}
.feature__item h2.archive__item-title {
	margin-top: 0.3em;
}
.feature__item .btn--primary {
	float: right;
	margin-bottom: 1em;
}
h1 img {
    border-radius: 0.3em;
    height: 2.5em;
}
</style>
  </head>

  <body class="layout--question">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/e-assessment-research-agenda/">
          Research agenda for e-assessment of university mathematics
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/e-assessment-research-agenda/contributors">Contributors</a>
            </li><li class="masthead__menu-item">
              <a href="/e-assessment-research-agenda/themes">Themes</a>
            </li><li class="masthead__menu-item">
              <a href="/e-assessment-research-agenda/questions">Questions</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  


  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Q3">
    <meta itemprop="description" content="Diagnosing and responding in detail to students’ specific errors/misconceptions has become perceived as highly valuable, and e-assessment systems have features that can facilitate this. But might it be more efficient overall to avoid attempting to diagnose errors after the fact, and instead “treat” everyone by addressing known typical errors in other ways?">
    <meta itemprop="datePublished" content="2021-10-14T14:01:36+00:00">
    

    <div class="page__inner-wrap">

      <section class="page__content e-content" itemprop="text">
        
        
<p><a href="../themes/errors-and-feedback" class="btn btn--inverse">Errors and feedback</a> &gt;  <a href="../themes/optimising-feedback-efforts" class="btn btn--inverse">Optimising feedback efforts</a></p>

<!-- <h1>Q3: Under what circumstances is diagnosing errors/misconceptions worth the extra effort, as compared with generally addressing errors known to be typical?</h1> -->
<p></p>
<h1><span class="question_num" style="font-weight:normal; font-size: 70%">Question 3</span><br>Under what circumstances is diagnosing errors/misconceptions worth the extra effort, as compared with generally addressing errors known to be typical?</h1>

<ul>


    
	  
	  
		<li><a href="/e-assessment-research-agenda/contributors/timlowe.html"><img src="https://github.com/timlowe.png?size=100" style="border-radius: 50%;width: 1.5em;height: 1.5em;margin: auto 0.5em auto -2em;" />Tim Lowe</a></li>
	  
    
	  
	  
		<li><a href="/e-assessment-research-agenda/contributors/georgekinnear.html"><img src="https://github.com/georgekinnear.png?size=100" style="border-radius: 50%;width: 1.5em;height: 1.5em;margin: auto 0.5em auto -2em;" />George Kinnear</a></li>
	  
    
	  
	  
		<li><a href="/e-assessment-research-agenda/contributors/prowlett.html"><img src="https://github.com/prowlett.png?size=100" style="border-radius: 50%;width: 1.5em;height: 1.5em;margin: auto 0.5em auto -2em;" />Peter Rowlett</a></li>
	  
    
	  
	  
		<li><a href="/e-assessment-research-agenda/contributors/colinfoster77.html"><img src="https://github.com/colinfoster77.png?size=100" style="border-radius: 50%;width: 1.5em;height: 1.5em;margin: auto 0.5em auto -2em;" />Colin Foster</a></li>
	  
    

</ul>

<p>Diagnosing and responding in detail to students’ specific errors/misconceptions has become perceived as highly valuable, and e-assessment systems have features that can facilitate this. But might it be more efficient overall to avoid attempting to diagnose errors after the fact, and instead “treat” everyone by addressing known typical errors in other ways?</p>

<h2 id="what-motivates-this-question">What motivates this question?</h2>

<p>Recent research suggests that “elaborated feedback” is more useful than simply giving correct/incorrect feedback (Attali &amp; van der Kleij, 2017). Moreover, results from a recent small-scale study (Pinkernell et al., 2020) suggest that tailored feedback based on error analysis can be more effective than giving a generic model solution as feedback.</p>

<p>However, devising this feedback and implementing it in an e-assessment system requires up-front effort from the teacher. That effort could perhaps be better spent in other ways.</p>

<p>Moreover, such specific feedback may be more valuable where the difficulty is in some way unusual and requires bespoke intervention – something that is perhaps better achieved with a 1-1 interaction rather than being mediated through an e-assessment system.</p>

<p>Although the personalised nature of e-assessment feedback may be advantageous, it may be that detailed feedback doesn’t always help students to learn. Rønning (2017) has 60% of student questionnaire respondents agreeing that they learn a lot from doing e-assessment problems, but reports that this is low compared with other learning resources. Robinson et al. (2012) report concern from lecturers that, while e-assessment confirms to “the most able” that they “have carried out the procedure correctly,” it may “struggle to provide the feedback necessary to facilitate understanding in weaker students”. This is because the feedback “isn’t much more than another worked example, as you find in the lecture notes, or as you find in the textbooks”.</p>

<h2 id="what-might-an-answer-look-like">What might an answer look like?</h2>

<p>Would need to decide what consitutes “extra effort” which may depend on the life of the quiz and the number of expected attempts. It may also be the case that some diagnosis can happen with very little extra effort, e.g. the way that some STACK <a href="http://docs.stack-assessment.org/en/Authoring/Answer_tests/">“answer tests”</a> provide feedback on common errors. Similarly, e-assessment systems may have features to report on frequent wrong answers, that could help the teacher to diagnose common errors.</p>

<p>The question asks “under what circumstances?” and these may include:</p>

<ul>
  <li>Mode of study of the student. Diagnosing errors may be of more importance to a student without easy access to a teacher.</li>
  <li>Topic. Some topics may have a small number of very well-defined errors/misconceptions; for other topics we may just not know, or we may know that difficulties are very diverse.</li>
</ul>

<p>Determining whether it is “worth” the extra effort could be based on quantitative measures (e.g. studying whether the presence of diagnostic feedback during practice leads to better performance on a subsequent test) or qualitative analysis (e.g. of students’ perceptions of the usefulness of the feedback).</p>

<h2 id="related-questions">Related questions</h2>

<ul>
  <li>This is closely related to <a href="Q4">Q4</a> which asks whether common errors might be better addressed up-front rather than in feedback. (In fact, Q4 is perhaps just a sub-question of this one, as an example of a specific way of “generally addressing errors known to be typical”).</li>
  <li>The issue of common errors is also addressed in <a href="Q1">Q1: Do the errors students make in e-assessments differ from those they make in paper-based assessments?</a>, <a href="Q2">Q2: What are the approaches to detecting and feeding back on students’ errors? </a> and <a href="Q5">Q5: What common errors do students make when answering online assessment questions?</a>.</li>
</ul>

<h2 id="references">References</h2>

<p>Attali, Y., &amp; van der Kleij, F. (2017). Effects of feedback elaboration and feedback timing during computer-based practice in mathematics problem solving. Computers and Education, 110, 154–169. https://doi.org/10.1016/j.compedu.2017.03.012</p>

<p>Pinkernell, G., Gulden, L., &amp; Kalz, M. (2020). Automated feedback at task level: Error analysis or worked out examples – which type is more effective? Proceedings of the 14th International Conference on Technology in Mathematics Teaching – ICTMT 14: Essen, Germany, 221. https://doi.org/10/ggw55s</p>

<p>Robinson, C.L., Hernandez-Martinez, P. &amp; Broughton, S. (2012). Mathematics Lecturers’ Practice and Perception of Computer-Aided Assessment. In: P. Iannone &amp; A. Simpson (Eds.), Mapping University Mathematics Assessment Practices (pp. 105-117). Norwich: University of East Anglia.</p>

<p>Rønning, F. (2017). Influence of computer-aided assessment on ways of working with mathematics. Teaching Mathematics and its Applications, 36(2), 94-107. https://doi.org/10.1093/teamat/hrx001</p>

        
      </section>

      <footer class="page__meta">
        
        


        <!-- 

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-10-14T14:01:36+00:00">October 14, 2021</time></p>

 -->
		 <i class="fab fa-fw fa-github"></i></span> <a href="https://github.com/maths/e-assessment-research-agenda/tree/main/_questions/Q3.md">Source on GitHub</a>
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/e-assessment-research-agenda/questions/Q29.html" class="pagination--pager" title="Q29
">Previous</a>
    
    
      <a href="/e-assessment-research-agenda/questions/Q30.html" class="pagination--pager" title="Q30
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Research agenda for e-assessment of university mathematics. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/e-assessment-research-agenda/assets/js/main.min.js"></script>










  </body>
</html>
